{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWjp0YakvnjK"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.nn.utils.rnn import *\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_FQdqcCbdf_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if GPU else \"cpu\")\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 0 if cuda else 0\n",
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete, took 4 seconds\n",
      "# Images loaded:  300\n"
     ]
    }
   ],
   "source": [
    "numDataPointsWanted = 300\n",
    "X = np.zeros((numDataPointsWanted, 3, 480, 640))\n",
    "Y = np.zeros((numDataPointsWanted, 3))\n",
    "dataType = \"center\"\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "root_path = \"./\"\n",
    "with open(root_path + \"labels.txt\") as f:\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        [filename, radians, torque, speed] = line.split(' ')\n",
    "\n",
    "        if filename[0:6] == \"center\":\n",
    "            with Image.open(root_path + filename) as img:\n",
    "                X[i,:,:,:] = (transform(img.convert('RGB')))\n",
    "            Y[i,0] = (((float(radians) * 180.0)/np.pi))\n",
    "            Y[i,1] = float(torque)\n",
    "            Y[i,2] = float(speed)\n",
    "            i += 1\n",
    "            \n",
    "        if i == numDataPointsWanted: break\n",
    "    end = time.time()\n",
    "    \n",
    "\n",
    "print(\"Data loading complete, took\", int(end - start), \"seconds\")\n",
    "print('# Images loaded: ', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, valX, trainY, valY = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-AvSJUVAdby"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X, Y, seq_len):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X) // self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = self.seq_len * index\n",
    "        return self.X[idx:idx + self.seq_len], self.Y[idx + self.seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "num_workers = 0 if cuda else 0\n",
    "\n",
    "train_set = Dataset(trainX, trainY, 15)\n",
    "train_dataloader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "val_set = Dataset(valX, valY, 15)\n",
    "val_dataloader = data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Whip(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_size, output_size):\n",
    "        super(Whip, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=(1, 4, 4), stride=2, padding=2)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 12, 12), stride=4, padding=2)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(out_channels, out_channels, kernel_size=(1, 4, 4), stride=2, padding=2)\n",
    "        self.bn3 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.avgpool = nn.AvgPool3d(1)\n",
    "        \n",
    "#         self.convLSTM = ConvLSTM(input_size=(30, 40), input_dim=out_channels, \n",
    "#                                     hidden_dim=out_channels//2, kernel_size=(3, 3), num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x) \n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        output = self.avgpool(output)\n",
    "        \n",
    "        hidden = None\n",
    "#         output, hidden = self.convLSTM(output, hidden)\n",
    "        \n",
    "        featuresV = output.reshape(output.size(0), -1)\n",
    "        output = self.fc(featuresV)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whip(\n",
      "  (conv1): Conv3d(15, 13, kernel_size=(1, 4, 4), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "  (bn1): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv3d(13, 13, kernel_size=(3, 12, 12), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "  (bn2): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv3d(13, 13, kernel_size=(1, 4, 4), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "  (bn3): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (avgpool): AvgPool3d(kernel_size=1, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=46800, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "context_size = 15\n",
    "out_channels = 13\n",
    "input_size = 46800\n",
    "\n",
    "# we will be predicting angle, torque, and speed\n",
    "output_size = 3\n",
    "model = Whip(context_size, out_channels, input_size, output_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x, y):\n",
    "    total = 0\n",
    "    for v in range(len(x)):\n",
    "        if x[v] and y[v]:\n",
    "            total += 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6nDA4eylV6N"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, save):\n",
    "    EPOCH_TRAIN_LOSSES = []\n",
    "    EPOCH_VAL_LOSSES = []\n",
    "    EPOCH_TRAIN_ACC = []\n",
    "    EPOCH_VAL_ACC = []\n",
    "    train_a_acc = []\n",
    "    val_a_acc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        running_train_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "        train_correct = 0.0\n",
    "        val_correct = 0.0\n",
    "        train_total = 0.0\n",
    "        val_total = 0.0\n",
    "               \n",
    "        t_correct_predictions_0_5 = 0.0\n",
    "        t_correct_predictions_1 = 0.0\n",
    "        t_correct_predictions_2 = 0.0\n",
    "        t_correct_predictions_5 = 0.0\n",
    "        t_correct_predictions_g_5 = 0.0\n",
    "        \n",
    "        v_correct_predictions_0_5 = 0.0\n",
    "        v_correct_predictions_1 = 0.0\n",
    "        v_correct_predictions_2 = 0.0\n",
    "        v_correct_predictions_5 = 0.0\n",
    "        v_correct_predictions_g_5 = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (x, label) in enumerate(train_dataloader):\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y = model(x.float()).double().squeeze(1)\n",
    "            \n",
    "            loss = criterion(y, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            predicted_angles = y[0]\n",
    "            label_angles = label[0]\n",
    "            train_correct += torch.sum(torch.abs(predicted_angles - label_angles) < 0.1).item()\n",
    "            t_correct_predictions_0_5 += torch.sum(torch.abs(predicted_angles - label_angles) <= 0.5).item()\n",
    "            t_correct_predictions_1 += combine(torch.abs(predicted_angles - label_angles) > 0.5,  torch.abs(predicted_angles - label_angles) <= 1)\n",
    "            t_correct_predictions_2 += combine(torch.abs(predicted_angles - label_angles) > 1,  torch.abs(predicted_angles - label_angles) <= 2)\n",
    "            t_correct_predictions_5 += combine(torch.abs(predicted_angles - label_angles) > 2,  torch.abs(predicted_angles - label_angles) <= 5)\n",
    "            v_correct_predictions_g_5 += torch.sum(torch.abs(predicted_angles - label_angles) > 5).item()\n",
    "            train_total += label_angles.size(0)\n",
    "            \n",
    "            del x\n",
    "            del label\n",
    "                    \n",
    "        train_a_a = [t_correct_predictions_0_5, t_correct_predictions_1, t_correct_predictions_2, t_correct_predictions_5, t_correct_predictions_g_5]\n",
    "        train_a_acc.append(train_a_a)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (x, label) in enumerate(val_dataloader):\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                y = model(x.float()).double().squeeze(1)\n",
    "                \n",
    "                loss = criterion(y, label)\n",
    "\n",
    "                running_val_loss += loss.item()\n",
    "                predicted_angles = y[0]\n",
    "                label_angles = label[0]\n",
    "                val_correct += torch.sum(torch.abs(predicted_angles - label_angles) < 0.1).item()\n",
    "                v_correct_predictions_0_5 += torch.sum(torch.abs(predicted_angles - label_angles) <= 0.5).item()\n",
    "                v_correct_predictions_1 += combine(torch.abs(predicted_angles - label_angles) > 0.5,  torch.abs(predicted_angles - label_angles) <= 1)\n",
    "                v_correct_predictions_2 += combine(torch.abs(predicted_angles - label_angles) > 1,  torch.abs(predicted_angles - label_angles) <= 2)\n",
    "                v_correct_predictions_5 += combine(torch.abs(predicted_angles - label_angles) > 2,  torch.abs(predicted_angles - label_angles) <= 5)\n",
    "                v_correct_predictions_g_5 += torch.sum(torch.abs(predicted_angles - label_angles) > 5).item()\n",
    "                val_total += label_angles.size(0)\n",
    "                \n",
    "            val_a_a = [v_correct_predictions_0_5, v_correct_predictions_1, v_correct_predictions_2, v_correct_predictions_5, v_correct_predictions_g_5]\n",
    "            val_a_acc.append(val_a_a)\n",
    "                \n",
    "        train_acc = (train_correct / (train_total))*100\n",
    "        val_acc = (val_correct / (val_total))*100\n",
    "        tloss = running_train_loss / len(train_dataloader)\n",
    "        vloss = running_val_loss/ len(val_dataloader)\n",
    "\n",
    "        print(\"EPOCH\", epoch, \"\\t\\tTook\", int(time.time() - start), \"s\")\n",
    "        print(\"Train Acc:\", train_acc, \"\\tVal Acc:\", val_acc)\n",
    "        print(\"Avg Train Loss:\", tloss, \"\\tAvg Val Loss:\", vloss)\n",
    "\n",
    "        scheduler.step(vloss)\n",
    "\n",
    "        EPOCH_TRAIN_LOSSES.append(tloss)\n",
    "        EPOCH_VAL_LOSSES.append(vloss)\n",
    "        EPOCH_TRAIN_ACC.append(train_acc)\n",
    "        EPOCH_VAL_ACC.append(val_acc)\n",
    "\n",
    "        if save:\n",
    "            torch.save(model.state_dict(), './model_' + str(epoch + 1) + '_' + str(val_acc) + '.pt')\n",
    "            \n",
    "    return EPOCH_TRAIN_LOSSES, EPOCH_VAL_LOSSES, EPOCH_TRAIN_ACC, EPOCH_VAL_ACC, val_a_acc, train_a_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Took 33 s\n",
      "Train Acc: 4.761904761904762 Val Acc: 11.11111111111111\n",
      "Avg Train Loss: 7.9671636295844985 Avg Val Loss: 117.09070854836399\n",
      "Epoch 1  Took 34 s\n",
      "Train Acc: 4.761904761904762 Val Acc: 0.0\n",
      "Avg Train Loss: 13.068651519256646 Avg Val Loss: 85.30155254776155\n",
      "Epoch 2  Took 30 s\n",
      "Train Acc: 0.0 Val Acc: 11.11111111111111\n",
      "Avg Train Loss: 5.258509106190407 Avg Val Loss: 76.39166465605946\n",
      "Epoch 3  Took 26 s\n",
      "Train Acc: 0.0 Val Acc: 11.11111111111111\n",
      "Avg Train Loss: 2.605073006538884 Avg Val Loss: 49.74188311403517\n",
      "Epoch 4  Took 28 s\n",
      "Train Acc: 4.761904761904762 Val Acc: 11.11111111111111\n",
      "Avg Train Loss: 3.719161066516466 Avg Val Loss: 31.232043613123235\n",
      "Epoch 5  Took 27 s\n",
      "Train Acc: 14.285714285714285 Val Acc: 11.11111111111111\n",
      "Avg Train Loss: 2.4621133901009165 Avg Val Loss: 20.95434440675994\n",
      "Epoch 6  Took 27 s\n",
      "Train Acc: 4.761904761904762 Val Acc: 22.22222222222222\n",
      "Avg Train Loss: 3.2779420196257023 Avg Val Loss: 9.907844510020544\n",
      "Epoch 7  Took 28 s\n",
      "Train Acc: 19.047619047619047 Val Acc: 22.22222222222222\n",
      "Avg Train Loss: 1.8925968037108298 Avg Val Loss: 3.086413749275314\n",
      "Epoch 8  Took 29 s\n",
      "Train Acc: 14.285714285714285 Val Acc: 22.22222222222222\n",
      "Avg Train Loss: 2.7380741526240584 Avg Val Loss: 1.7169819413686913\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-585765720d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "n_epochs = 9\n",
    "EPOCH_TRAIN_LOSSES, EPOCH_VAL_LOSSES, EPOCH_TRAIN_ACC, EPOCH_VAL_ACC, val_a_acc, train_a_acc = train(n_epochs, model, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(n_epochs)\n",
    "\n",
    "rangeVi = 2\n",
    "rangeVf = 9\n",
    "plt.plot(x[rangeVi:rangeVf], t_l[rangeVi:rangeVf], label=\"Train\")\n",
    "plt.plot(x[rangeVi:rangeVf], v_l[rangeVi:rangeVf], label=\"Validation\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Epochs vs Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('RNNLossFinal_ResNet_34.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, t_a, label=\"Train\")\n",
    "plt.plot(x, v_a, label=\"Validation\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Epochs vs Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig('RNNAccuracyFinal.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "steering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
