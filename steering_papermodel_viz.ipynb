{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWjp0YakvnjK"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.nn.utils.rnn import *\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import time\n",
    "import pdb\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_FQdqcCbdf_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if GPU else \"cpu\")\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 0 if cuda else 0\n",
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image names only..\n",
      "Data loading complete, took 0 seconds\n",
      "# Images loaded:  33808\n"
     ]
    }
   ],
   "source": [
    "# Image loading hyperparameters\n",
    "numDataPointsWanted = 33808     # max number is 33808\n",
    "LOADIMAGES = False              # True if we want to pre-load all images (usually results in MEM errors)\n",
    "\n",
    "CROPBOX = (0, 200, 640, 480)\n",
    "IMG_SIZE = (320, 240)\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "root_path = \"./\"\n",
    "\n",
    "def load_cropped_resized_image(filename):\n",
    "    with Image.open(root_path + filename) as img:\n",
    "         return transform(img.crop(CROPBOX).resize(IMG_SIZE).convert('RGB'))\n",
    "\n",
    "if LOADIMAGES:\n",
    "    print(\"Pre-loading all images..\")\n",
    "    X = np.zeros((numDataPointsWanted, 3, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "else:\n",
    "    print(\"Loading image names only..\")\n",
    "    X = np.zeros((numDataPointsWanted), dtype=object)\n",
    "Y = np.zeros((numDataPointsWanted, 3))\n",
    "\n",
    "\n",
    "with open(root_path + \"labels.txt\") as f:\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        [filename, radians, torque, speed] = line.split(' ')\n",
    "\n",
    "        if LOADIMAGES:\n",
    "            X[i,:,:,:] = load_cropped_resized_image(filename)\n",
    "        else:\n",
    "            X[i] = filename\n",
    "        Y[i,0] = (((float(radians) * 180.0) / np.pi))\n",
    "        Y[i,1] = float(torque)\n",
    "        Y[i,2] = float(speed)\n",
    "        i += 1\n",
    "            \n",
    "        if i == numDataPointsWanted: break\n",
    "    end = time.time()\n",
    "    \n",
    "\n",
    "print(\"Data loading complete, took\", int(end - start), \"seconds\")\n",
    "print('# Images loaded: ', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop# 0\n",
      "mean_result=  [-0.52242762 -0.09517625 15.62886386]\n",
      "Lsteer=  15.60814343725929\n",
      "Lvel =  0.7905445803808853\n",
      "Ltor =  5.741342040929538\n",
      "Loss =  162.61332099390333\n",
      "loop# 1\n",
      "mean_result=  [-0.52946468 -0.09049424 15.61134776]\n",
      "Lsteer=  15.375340633769202\n",
      "Lvel =  0.7856847209645648\n",
      "Ltor =  5.693067011220797\n",
      "Loss =  160.23215806987736\n",
      "loop# 2\n",
      "mean_result=  [-0.46514378 -0.09160076 15.60036003]\n",
      "Lsteer=  15.458224786942548\n",
      "Lvel =  0.7859859859211787\n",
      "Ltor =  5.725626924659013\n",
      "Loss =  161.09386078000568\n",
      "loop# 3\n",
      "mean_result=  [-0.48978477 -0.0917271  15.63092917]\n",
      "Lsteer=  15.708703114596986\n",
      "Lvel =  0.7898905621314549\n",
      "Ltor =  5.696143409241092\n",
      "Loss =  163.57306511734242\n",
      "loop# 4\n",
      "mean_result=  [-0.46463095 -0.08817039 15.6282872 ]\n",
      "Lsteer=  15.55031454939187\n",
      "Lvel =  0.7791674525241242\n",
      "Ltor =  5.712299375621547\n",
      "Loss =  161.99461232206437\n",
      "loop# 5\n",
      "mean_result=  [-0.51542123 -0.09162771 15.62324943]\n",
      "Lsteer=  15.576015118062516\n",
      "Lvel =  0.7872744235430792\n",
      "Ltor =  5.746488695092643\n",
      "Loss =  162.29391429926088\n",
      "loop# 6\n",
      "mean_result=  [-0.51175621 -0.09145072 15.6007294 ]\n",
      "Lsteer=  15.26765633229357\n",
      "Lvel =  0.7754670357898374\n",
      "Ltor =  5.698060274643934\n",
      "Loss =  159.15009063336944\n",
      "loop# 7\n",
      "mean_result=  [-0.50286556 -0.09140423 15.62365182]\n",
      "Lsteer=  15.963593148506776\n",
      "Lvel =  0.7953103143121746\n",
      "Ltor =  5.6765130741496685\n",
      "Loss =  166.10775487352961\n",
      "loop# 8\n",
      "mean_result=  [-0.53522877 -0.09399941 15.62004898]\n",
      "Lsteer=  15.661876761752355\n",
      "Lvel =  0.7845456370211833\n",
      "Ltor =  5.668485259814825\n",
      "Loss =  163.07179851435956\n",
      "loop# 9\n",
      "mean_result=  [-0.54264996 -0.09407899 15.65671879]\n",
      "Lsteer=  15.718450651098957\n",
      "Lvel =  0.7824458439576002\n",
      "Ltor =  5.73255317867434\n",
      "Loss =  163.6995055336215\n",
      "[15.60814343725929, 15.375340633769202, 15.458224786942548, 15.708703114596986, 15.55031454939187, 15.576015118062516, 15.26765633229357, 15.963593148506776, 15.661876761752355, 15.718450651098957]\n"
     ]
    }
   ],
   "source": [
    "Lsteer = []\n",
    "Lnet = []\n",
    "for i in range(10):\n",
    "    print('loop#',i)\n",
    "    trainX, valX, trainY, valY = train_test_split(X, Y, test_size=0.30)\n",
    "\n",
    "    # Mean prediction based on training label\n",
    "\n",
    "    mean_result = np.mean(trainY,axis=0)\n",
    "    print('mean_result= ' ,mean_result)\n",
    "\n",
    "    # Make prediction array\n",
    "    mean_prediction = np.transpose(mean_result.reshape((3,1)) * np.ones([1,valY.shape[0]]))\n",
    "\n",
    "    # Evaluate RMSE loss between ground truth (valY) and mean_prediction\n",
    "    steer_loss = math.sqrt(mean_squared_error(valY[:,0],mean_prediction[:,0])) #,squared=False) some reason not supported?\n",
    "    velocity_loss = math.sqrt(mean_squared_error(valY[:,1],mean_prediction[:,1])) #,squared=False)\n",
    "    torque_loss = math.sqrt(mean_squared_error(valY[:,2],mean_prediction[:,2])) #,squared=False)\n",
    "\n",
    "    angle_loss_weight=10\n",
    "    total_loss = angle_loss_weight*steer_loss + velocity_loss + torque_loss\n",
    "\n",
    "    Lsteer.append(steer_loss)\n",
    "    Lnet.append(total_loss)\n",
    "    print('Lsteer= ',steer_loss)\n",
    "    print('Lvel = ', velocity_loss)\n",
    "    print('Ltor = ', torque_loss)\n",
    "    print('Loss = ', total_loss)   \n",
    "\n",
    "print(Lsteer)\n",
    "# print(valY[:,0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-AvSJUVAdby"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X, Y, seq_len, loaded_images):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.seq_len = seq_len\n",
    "        self.loaded_images = loaded_images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X) // self.seq_len - 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = self.seq_len * index\n",
    "        if not self.loaded_images:\n",
    "            x = np.zeros((self.seq_len, 3, IMG_SIZE[1], IMG_SIZE[0]))\n",
    "            for i in range(self.seq_len):\n",
    "                x[i,:,:,:] = load_cropped_resized_image(self.X[idx + i])\n",
    "            return x, self.Y[idx + self.seq_len]\n",
    "        \n",
    "        return self.X[idx:idx + self.seq_len], self.Y[idx + self.seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "SEQ_LEN = 15 \n",
    "num_workers = 0 if cuda else 0\n",
    "\n",
    "train_set = Dataset(trainX, trainY, SEQ_LEN, LOADIMAGES)\n",
    "train_dataloader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "val_set = Dataset(valX, valY, SEQ_LEN, LOADIMAGES)\n",
    "val_dataloader = data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "\n",
    "print(len(train_dataloader)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of cropped and resized image\n",
    "\n",
    "We really only need this because only the road part of the image is relevant for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_set.__getitem__(0)[0][0]\n",
    "x_tru_steer = train_set.__getitem__(0)[1][0]\n",
    "print(x.shape)\n",
    "print(x_tru_steer)\n",
    "x = x.transpose(1, 2, 0)  #W*H*channel\n",
    "Image.fromarray((x * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional LSTM model, as in the paper \n",
    "#   Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\n",
    "# https://github.com/automan000/Convolutional_LSTM_PyTorch/blob/master/convolution_lstm.py\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        assert hidden_channels % 2 == 0\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_features = 4\n",
    "\n",
    "        self.padding = int((kernel_size - 1) / 2)\n",
    "\n",
    "        self.Wxi = nn.Conv2d(self.input_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=True)\n",
    "        self.Whi = nn.Conv2d(self.hidden_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=False)\n",
    "        self.Wxf = nn.Conv2d(self.input_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=True)\n",
    "        self.Whf = nn.Conv2d(self.hidden_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=False)\n",
    "        self.Wxc = nn.Conv2d(self.input_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=True)\n",
    "        self.Whc = nn.Conv2d(self.hidden_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=False)\n",
    "        self.Wxo = nn.Conv2d(self.input_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=True)\n",
    "        self.Who = nn.Conv2d(self.hidden_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=False)\n",
    "\n",
    "        self.Wci = None\n",
    "        self.Wcf = None\n",
    "        self.Wco = None\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        ci = torch.sigmoid(self.Wxi(x) + self.Whi(h) + c * self.Wci)\n",
    "        cf = torch.sigmoid(self.Wxf(x) + self.Whf(h) + c * self.Wcf)\n",
    "        cc = cf * c + ci * torch.tanh(self.Wxc(x) + self.Whc(h))\n",
    "        co = torch.sigmoid(self.Wxo(x) + self.Who(h) + cc * self.Wco)\n",
    "        ch = co * torch.tanh(cc)\n",
    "        return ch, cc\n",
    "\n",
    "    def init_hidden(self, batch_size, hidden, shape):\n",
    "        if self.Wci is None:\n",
    "            self.Wci = Variable(torch.zeros(1, hidden, shape[0], shape[1])).to(device)\n",
    "            self.Wcf = Variable(torch.zeros(1, hidden, shape[0], shape[1])).to(device)\n",
    "            self.Wco = Variable(torch.zeros(1, hidden, shape[0], shape[1])).to(device)\n",
    "        else:\n",
    "            assert shape[0] == self.Wci.size()[2], 'Input Height Mismatched!'\n",
    "            assert shape[1] == self.Wci.size()[3], 'Input Width Mismatched!'\n",
    "        return (Variable(torch.zeros(batch_size, hidden, shape[0], shape[1])).to(device),\n",
    "                Variable(torch.zeros(batch_size, hidden, shape[0], shape[1])).to(device))\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    # input_channels corresponds to the first input feature map\n",
    "    # hidden state is a list of succeeding lstm layers.\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, step=1, effective_step=[1]):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.input_channels = [input_channels] + hidden_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = len(hidden_channels)\n",
    "        self.step = step\n",
    "        self.effective_step = effective_step\n",
    "        self._all_layers = []\n",
    "        for i in range(self.num_layers):\n",
    "            name = 'cell{}'.format(i)\n",
    "            cell = ConvLSTMCell(self.input_channels[i], self.hidden_channels[i], self.kernel_size)\n",
    "            setattr(self, name, cell)\n",
    "            self._all_layers.append(cell)\n",
    "\n",
    "    def forward(self, input):\n",
    "        internal_state = []\n",
    "        outputs = []\n",
    "        for step in range(self.step):\n",
    "            x = input\n",
    "            for i in range(self.num_layers):\n",
    "                # all cells are initialized in the first step\n",
    "                name = 'cell{}'.format(i)\n",
    "                if step == 0:\n",
    "                    bsize, _, height, width = x.size()\n",
    "                    (h, c) = getattr(self, name).init_hidden(batch_size=bsize, hidden=self.hidden_channels[i],\n",
    "                                                             shape=(height, width))\n",
    "                    internal_state.append((h, c))\n",
    "\n",
    "                (h, c) = internal_state[i]\n",
    "                x, new_c = getattr(self, name)(x, h, c)\n",
    "                internal_state[i] = (x, new_c)\n",
    "            outputs.append(x)\n",
    "\n",
    "        return outputs, (x, new_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replicate of the model in paper (WIP)\n",
    "# # https://arxiv.org/pdf/1708.03798.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Whip(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_size, output_size):\n",
    "        super(Whip, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=(1, 4, 4), stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 12, 12), stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(out_channels, out_channels, kernel_size=(1, 4, 4), stride=2)\n",
    "        self.bn3 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.avgpool = nn.AvgPool3d(1)\n",
    "        \n",
    "        self.convLSTM = ConvLSTM(input_channels=out_channels, hidden_channels= [512, 128, 64, 32], \n",
    "                                 kernel_size=3)\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x) \n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "#         print('relu3,'+ str(output.shape))\n",
    "        \n",
    "        output = self.avgpool(output).squeeze(2)\n",
    "        \n",
    "#         print('avgPool,'+str(output.shape))\n",
    "        output, hidden = self.convLSTM(output)\n",
    "        output = output[0]\n",
    "        \n",
    "        featuresV = output.reshape(output.size(0), -1)\n",
    "        output = self.fc(featuresV)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128, hidden_dim=64, out_dim=3, nlayers=3):\n",
    "        super(predictNet,self).__init__()\n",
    "        self.lstm = nn.LSTMCell(input_size=feature_dim+out_dim, hidden_size=hidden_dim, bias=False)\n",
    "        self.fc = nn.Linear(feature_dim+hidden_dim+out_dim, out_dim)\n",
    "    \n",
    "    def forward(self, features): \n",
    "        predictions = []\n",
    "        out = torch.zeros((features.shape[0],3)).to(device) #previous speed,torque,angle prediction\n",
    "        for i in range(features.shape[1]):\n",
    "            concat1 = torch.cat([features[:,i,:], out], dim=1) #[batch,seq_len,features]\n",
    "            out_lstm, _ = self.lstm(concat1)\n",
    "            concat2 = torch.cat([out_lstm, features[:,i,:], out], dim=1)\n",
    "            out = self.fc(concat2) #[batch,3]\n",
    "            \n",
    "            predictions.append(out.unsqueeze(1))\n",
    "        \n",
    "        return torch.cat(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class superModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_size, output_size=128, hidden_dim=64, out_dim=3, nlayers=3):\n",
    "        super(superModel, self).__init__()\n",
    "        self.whip = Whip(in_channels, out_channels, input_size, output_size).to(device)\n",
    "        self.predictNet = predictNet().to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.whip(x)\n",
    "        predictions = self.predictNet(features.to(device))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x, y):\n",
    "    total = 0\n",
    "    for v in range(len(x)):\n",
    "        if x[v] and y[v]:\n",
    "            total += 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_loss_weight=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6nDA4eylV6N"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, save, optimizer, scheduler, criterion):\n",
    "    EPOCH_TRAIN_LOSSES = []\n",
    "    EPOCH_VAL_LOSSES = []\n",
    "    EPOCH_TRAIN_ACC = []\n",
    "    EPOCH_VAL_ACC = []\n",
    "    train_a_acc = []\n",
    "    val_a_acc = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        running_train_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "        running_val_acc = 0.0\n",
    "               \n",
    "        t_correct_predictions_0_5 = 0.0\n",
    "        t_correct_predictions_1 = 0.0\n",
    "        t_correct_predictions_2 = 0.0\n",
    "        t_correct_predictions_5 = 0.0\n",
    "        t_correct_predictions_g_5 = 0.0\n",
    "        \n",
    "        v_correct_predictions_0_5 = 0.0\n",
    "        v_correct_predictions_1 = 0.0\n",
    "        v_correct_predictions_2 = 0.0\n",
    "        v_correct_predictions_5 = 0.0\n",
    "        v_correct_predictions_g_5 = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (x, label) in enumerate(train_dataloader):\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y = model(x.float()).double().squeeze(1)\n",
    "            \n",
    "            loss = angle_loss_weight * criterion(y[:,0], label[:,0]) + \\\n",
    "                    criterion(y[:,1], label[:,1]) + \\\n",
    "                    criterion(y[:,2], label[:,2])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            predicted_angles = y[0]\n",
    "            label_angles = label[0]\n",
    "            running_train_acc += torch.mean(torch.abs(predicted_angles - label_angles)).item()\n",
    "            t_correct_predictions_0_5 += torch.sum(torch.abs(predicted_angles - label_angles) <= 0.5).item()\n",
    "            t_correct_predictions_1 += combine(torch.abs(predicted_angles - label_angles) > 0.5,  torch.abs(predicted_angles - label_angles) <= 1)\n",
    "            t_correct_predictions_2 += combine(torch.abs(predicted_angles - label_angles) > 1,  torch.abs(predicted_angles - label_angles) <= 2)\n",
    "            t_correct_predictions_5 += combine(torch.abs(predicted_angles - label_angles) > 2,  torch.abs(predicted_angles - label_angles) <= 5)\n",
    "            v_correct_predictions_g_5 += torch.sum(torch.abs(predicted_angles - label_angles) > 5).item()\n",
    "            \n",
    "            del x\n",
    "            del label\n",
    "                    \n",
    "        train_a_a = [t_correct_predictions_0_5, t_correct_predictions_1, t_correct_predictions_2, t_correct_predictions_5, t_correct_predictions_g_5]\n",
    "        train_a_acc.append(train_a_a)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (x, label) in enumerate(val_dataloader):\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                y = model(x.float()).double().squeeze(1)\n",
    "                \n",
    "                loss = angle_loss_weight * criterion(y[:,0], label[:,0]) + \\\n",
    "                            criterion(y[:,1], label[:,1]) +\\\n",
    "                            criterion(y[:,2], label[:,2])\n",
    "\n",
    "                running_val_loss += loss.item()\n",
    "                predicted_angles = y[0]\n",
    "                label_angles = label[0]\n",
    "                running_val_acc += torch.mean(torch.abs(predicted_angles - label_angles)).item()\n",
    "                v_correct_predictions_0_5 += torch.sum(torch.abs(predicted_angles - label_angles) <= 0.5).item()\n",
    "                v_correct_predictions_1 += combine(torch.abs(predicted_angles - label_angles) > 0.5,  torch.abs(predicted_angles - label_angles) <= 1)\n",
    "                v_correct_predictions_2 += combine(torch.abs(predicted_angles - label_angles) > 1,  torch.abs(predicted_angles - label_angles) <= 2)\n",
    "                v_correct_predictions_5 += combine(torch.abs(predicted_angles - label_angles) > 2,  torch.abs(predicted_angles - label_angles) <= 5)\n",
    "                v_correct_predictions_g_5 += torch.sum(torch.abs(predicted_angles - label_angles) > 5).item()\n",
    "                \n",
    "                del x\n",
    "                del label\n",
    "                \n",
    "            val_a_a = [v_correct_predictions_0_5, v_correct_predictions_1, v_correct_predictions_2, v_correct_predictions_5, v_correct_predictions_g_5]\n",
    "            val_a_acc.append(val_a_a)\n",
    "                \n",
    "        train_acc = running_train_acc / len(train_dataloader)\n",
    "        val_acc = running_val_acc / len(val_dataloader)\n",
    "        tloss = running_train_loss / len(train_dataloader)\n",
    "        vloss = running_val_loss/ len(val_dataloader)\n",
    "\n",
    "        print(\"EPOCH\", epoch, \"\\t\\tTook\", int(time.time() - start), \"s\")\n",
    "        print(\"Train Acc:\", round(train_acc, 4), \"\\tVal Acc:\", round(val_acc, 4))\n",
    "        print(\"Avg Train Loss:\", round(tloss, 4), \"\\tAvg Val Loss:\", round(vloss, 4))\n",
    "        print(\"===================================================================\")\n",
    "\n",
    "        scheduler.step(vloss)\n",
    "\n",
    "        EPOCH_TRAIN_LOSSES.append(tloss)\n",
    "        EPOCH_VAL_LOSSES.append(vloss)\n",
    "        EPOCH_TRAIN_ACC.append(train_acc)\n",
    "        EPOCH_VAL_ACC.append(val_acc)\n",
    "\n",
    "        if save:\n",
    "            torch.save(model.state_dict(), './model_' + str(epoch + 1) + '_' + str(val_acc) + '.pt')\n",
    "            \n",
    "    return EPOCH_TRAIN_LOSSES, EPOCH_VAL_LOSSES, EPOCH_TRAIN_ACC, EPOCH_VAL_ACC, val_a_acc, train_a_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 15\n",
    "out_channels = 13\n",
    "# input_size = 140448     # use this if using original image size\n",
    "input_size = 37*27\n",
    "\n",
    "# we will be predicting angle, torque, and speed\n",
    "# output_size = 3 #for whip?\n",
    "output_size=128 \n",
    "model = superModel(in_channels=context_size, out_channels=out_channels, input_size=input_size, output_size=128, hidden_dim=64, out_dim=3, nlayers=3)\n",
    "model = model.to(device) \n",
    "# model = Whip(context_size, out_channels, input_size, output_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)\n",
    "# sample = torch.zeros([13,15,1,4,4])\n",
    "# model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "results = train(n_epochs, model, True, optimizer, scheduler, criterion)\n",
    "[EPOCH_TRAIN_LOSSES, EPOCH_VAL_LOSSES, EPOCH_TRAIN_ACC, EPOCH_VAL_ACC, val_a_acc, train_a_acc] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ep = np.arange(n_epochs)\n",
    "\n",
    "rangeVi = 0\n",
    "rangeVf = n_epochs\n",
    "plt.plot(ep[rangeVi:rangeVf], EPOCH_TRAIN_LOSSES[rangeVi:rangeVf], label=\"Train\")\n",
    "plt.plot(ep[rangeVi:rangeVf], EPOCH_VAL_LOSSES[rangeVi:rangeVf], label=\"Validation\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Epochs vs Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('LossGraph.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ep[rangeVi:rangeVf], EPOCH_TRAIN_ACC[rangeVi:rangeVf], label=\"Train\")\n",
    "plt.plot(ep[rangeVi:rangeVf], EPOCH_VAL_ACC[rangeVi:rangeVf], label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Degree Distance\")\n",
    "plt.title(\"Epochs vs Average Degree Distance\")\n",
    "plt.legend()\n",
    "plt.savefig('AccuracyGraph.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "objects = ('[0, 0.5]', '(0.5, 1]', '(1, 2]', '(2, 5]', '(5, Inf.)')\n",
    "performanceV = val_a_acc[-1]\n",
    "performanceT = train_a_acc[0]\n",
    "\n",
    "x = np.arange(len(objects))\n",
    "width = 0.2 # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, performanceV, width, label=\"Validation\")\n",
    "rects1 = ax.bar(x + width/2, performanceT, width, label=\"Training\")\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Training Points')\n",
    "ax.set_title('Accuracy for Last Epoch')\n",
    "ax.set_xticks(x)\n",
    "plt.ylim(0, 1000)\n",
    "labels = []\n",
    "totalV = sum(performanceV)\n",
    "totalT = sum(performanceT)\n",
    "\n",
    "for x in range(len(objects)):\n",
    "    labels.append(objects[x] + \"\\n\" + str(int((performanceV[x]/totalV)*100)) + \"%,\" + str(int((performanceT[x]/totalT)*100)) + \"%\")\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "plt.savefig('Last_Epoch.png', dpi=300)\n",
    "\n",
    "objects = ('[0, 0.5]', '(0.5, 1]', '(1, 2]', '(2, 5]', '(5, Inf.)')\n",
    "performanceV = val_a_acc[0]\n",
    "performanceT = train_a_acc[-1]\n",
    "\n",
    "x = np.arange(len(objects))\n",
    "# print(v_all_a)\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, performanceV, width, label=\"Validation\")\n",
    "rects1 = ax.bar(x + width/2, performanceT, width, label=\"Training\")\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Training Points')\n",
    "ax.set_title('Accuracy for First Epoch')\n",
    "ax.set_xticks(x)\n",
    "plt.ylim(0, 1000)\n",
    "labels = []\n",
    "totalV = sum(performanceV)\n",
    "totalT = sum(performanceT)\n",
    "\n",
    "for x in range(len(objects)):\n",
    "    labels.append(objects[x] + \"\\n\" + str(int((performanceV[x]/totalV)*100)) + \"%,\" + str(int((performanceT[x]/totalT)*100)) + \"%\")\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "plt.savefig('Zero_Epoch.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of predicted vs actual steering angles with scene pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Pick out a couple good results from the dataset\n",
    "x_tru_steer = train_set.__getitem__(0)[1][0]\n",
    "x_predicted_steer = -12.0 # dummy input\n",
    "\n",
    "\n",
    "# Step 1: Graphically show the 2 steering angles in a steering circle\n",
    "fig, ax = plt.subplots()\n",
    "ax.set(xlim=(-1, 1), ylim = (-1, 1))\n",
    "\n",
    "wheel = plt.Circle((0, 0), .5,fill=False)\n",
    "ax.add_artist(wheel)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "def plot_ray(point, tru_angle, pred_angle, length):  \n",
    "    startx, starty = point\n",
    "    endy1 = starty + length * math.sin(math.radians(tru_angle+90.0))  #default is positive-x axis,\n",
    "    endx1 = startx + length * math.cos(math.radians(tru_angle+90.0))  #we need common driving angle\n",
    "    \n",
    "    endy2 = starty + length * math.sin(math.radians(pred_angle+90.0))  \n",
    "    endx2 = startx + length * math.cos(math.radians(pred_angle+90.0))  \n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('True steering angle (blue), predicted steering angle(red)')\n",
    "    ax1.plot([startx, endx1], [starty, endy1],'b')\n",
    "    ax2.plot([startx, endx2], [starty, endy2],'r')\n",
    "    \n",
    "    ax1.set_ylim([-1, 1])\n",
    "    ax1.set_xlim([-1, 1])\n",
    "    ax2.set_ylim([-1, 1])\n",
    "    ax2.set_xlim([-1, 1])\n",
    "    fig.show()\n",
    "  \n",
    "plot_ray([0,0],x_tru_steer,x_predicted_steer,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: display dashcam image, and bring context to actual numbers\n",
    "print(x.shape)  #240x320x3\n",
    "Image.fromarray((x * 255).astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "steering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
