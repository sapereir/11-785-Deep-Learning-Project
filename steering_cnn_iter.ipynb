{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWjp0YakvnjK"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.nn.utils.rnn import *\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from convLSTM import *\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_FQdqcCbdf_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if GPU else \"cpu\")\n",
    "cuda = torch.cuda.is_available()\n",
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.170618534088135 seconds\n",
      "Images:  300\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "dataType = \"center\"\n",
    "numDataPointsWanted = 300 #Might want to change this\n",
    "\n",
    "transform=transforms.ToTensor()\n",
    "root_path = \"./\"\n",
    "with open(root_path + \"labels.txt\") as f:\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        [filename, radians] = line.split(' ')\n",
    "        \n",
    "        if filename[0:4] == \"left\" and dataType == \"left\":\n",
    "            with Image.open(root_path + filename) as img:\n",
    "                X.append(transform(img.convert('RGB')))\n",
    "            Y.append(((float(radians) * 180.0)/np.pi))\n",
    "            i += 1\n",
    "            \n",
    "        if filename[0:5] == \"right\" and dataType == \"right\":\n",
    "            with Image.open(root_path + filename) as img:\n",
    "                X.append(transform(img.convert('RGB')))\n",
    "            Y.append(((float(radians) * 180.0)/np.pi))\n",
    "            i += 1\n",
    "                \n",
    "        if filename[0:6] == \"center\" and dataType == \"center\":\n",
    "            with Image.open(root_path + filename) as img:\n",
    "                X.append(transform(img.convert('RGB')))\n",
    "            Y.append((float(radians) * 180.0)/np.pi)\n",
    "            i += 1\n",
    "            \n",
    "        if i == numDataPointsWanted: break\n",
    "    end = time.time()\n",
    "    \n",
    "\n",
    "print(end - start, \"seconds\")\n",
    "print('Images: ', len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Model(data.Dataset):\n",
    "    def __init__(self, X, Y, context_size=15):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for i in range(context_size, len(X)):\n",
    "            x = [torch.as_tensor(arr) for arr in X[i-context_size:i]]\n",
    "            self.X.append(torch.stack(x))\n",
    "            self.Y.append(Y[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index].float(), self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "num_workers = 0 if cuda else 0 \n",
    "train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.20)\n",
    "\n",
    "train_set = Dataset_Model(train_X, train_Y, context_size=15)\n",
    "train_dataloader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "val_set = Dataset_Model(val_X, val_Y, context_size=15)\n",
    "val_dataloader = data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "45\n",
      "torch.Size([15, 3, 480, 640]) 0.4999999961268166\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "\n",
    "print(train_set.__getitem__(0)[0].shape, train_set.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Q7kgXqOJooJ"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=(1, 4, 4), stride=2, padding=2)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 12, 12), stride=4, padding=2)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(out_channels, out_channels, kernel_size=(1, 4, 4), stride=2, padding=2)\n",
    "        self.bn3 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.avgpool = nn.AvgPool3d(1)\n",
    "        \n",
    "#         self.convLSTM = ConvLSTM(input_size=(30, 40), input_dim=out_channels, \n",
    "#                                     hidden_dim=out_channels//2, kernel_size=(3, 3), num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x) \n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        output = self.avgpool(output)\n",
    "        \n",
    "#         print(output.shape)\n",
    "        hidden = None\n",
    "#         output, hidden = self.convLSTM(output, hidden)\n",
    "        \n",
    "        featuresV = output.reshape(output.size(0), -1)\n",
    "        output = self.fc(featuresV)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXbF3bm9eqsz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv3d(15, 13, kernel_size=(1, 4, 4), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "  (bn1): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv3d(13, 13, kernel_size=(3, 12, 12), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "  (bn2): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv3d(13, 13, kernel_size=(1, 4, 4), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "  (bn3): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (avgpool): AvgPool3d(kernel_size=1, stride=1, padding=0)\n",
      "  (convLSTM): ConvLSTM(\n",
      "    (cell_list): ModuleList(\n",
      "      (0): ConvLSTMCell(\n",
      "        (conv): Conv2d(19, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=46800, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "context_size = 15\n",
    "out_channels = 13\n",
    "input_size = 46800\n",
    "f_model = CNN(context_size, out_channels, input_size, 1).to(device)\n",
    "optimizer = torch.optim.Adam(f_model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x, y):\n",
    "    total = 0\n",
    "    for v in range(len(x)):\n",
    "        if x[v] and y[v]:\n",
    "            total += 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6nDA4eylV6N"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, save):\n",
    "    EPOCH_TRAIN_LOSSES = []\n",
    "    EPOCH_VAL_LOSSES = []\n",
    "    EPOCH_TRAIN_ACC = []\n",
    "    EPOCH_VAL_ACC = []\n",
    "    train_a_acc = []\n",
    "    val_a_acc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        running_train_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "        train_correct = 0.0\n",
    "        val_correct = 0.0\n",
    "        train_total = 0.0\n",
    "        val_total = 0.0\n",
    "               \n",
    "        t_correct_predictions_0_5 = 0.0\n",
    "        t_correct_predictions_1 = 0.0\n",
    "        t_correct_predictions_2 = 0.0\n",
    "        t_correct_predictions_5 = 0.0\n",
    "        t_correct_predictions_g_5 = 0.0\n",
    "        \n",
    "        v_correct_predictions_0_5 = 0.0\n",
    "        v_correct_predictions_1 = 0.0\n",
    "        v_correct_predictions_2 = 0.0\n",
    "        v_correct_predictions_5 = 0.0\n",
    "        v_correct_predictions_g_5 = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (x, label) in enumerate(train_dataloader):\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             s = time.time()\n",
    "            y = model(x.float()).double().squeeze(1)\n",
    "#             e = time.time()\n",
    "#             print(e - s, \"time for f pass\")\n",
    "            \n",
    "            loss = criterion(y, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            predicted = y            \n",
    "            train_correct += torch.sum(torch.abs(predicted - label) < 0.1).item()\n",
    "            t_correct_predictions_0_5 += torch.sum(torch.abs(predicted - label) <= 0.5).item()\n",
    "            t_correct_predictions_1 += combine(torch.abs(predicted - label) > 0.5,  torch.abs(predicted - label) <= 1)\n",
    "            t_correct_predictions_2 += combine(torch.abs(predicted - label) > 1,  torch.abs(predicted - label) <= 2)\n",
    "            t_correct_predictions_5 += combine(torch.abs(predicted - label) > 2,  torch.abs(predicted - label) <= 5)\n",
    "            v_correct_predictions_g_5 += torch.sum(torch.abs(predicted - label) > 5).item()\n",
    "            train_total += label.size(0)\n",
    "            \n",
    "            del x\n",
    "            del label\n",
    "                    \n",
    "        train_a_a = [t_correct_predictions_0_5, t_correct_predictions_1, t_correct_predictions_2, t_correct_predictions_5, t_correct_predictions_g_5]\n",
    "        train_a_acc.append(train_a_a)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (x, label) in enumerate(val_dataloader):\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                y = model(x.float()).double().squeeze(1)\n",
    "                \n",
    "                loss = criterion(y, label)\n",
    "\n",
    "                running_val_loss += loss.item()\n",
    "                predicted = y\n",
    "                val_correct += torch.sum(torch.abs(predicted - label) < 0.1).item()\n",
    "                v_correct_predictions_0_5 += torch.sum(torch.abs(predicted - label) <= 0.5).item()\n",
    "                v_correct_predictions_1 += combine(torch.abs(predicted - label) > 0.5,  torch.abs(predicted - label) <= 1)\n",
    "                v_correct_predictions_2 += combine(torch.abs(predicted - label) > 1,  torch.abs(predicted - label) <= 2)\n",
    "                v_correct_predictions_5 += combine(torch.abs(predicted - label) > 2,  torch.abs(predicted - label) <= 5)\n",
    "                v_correct_predictions_g_5 += torch.sum(torch.abs(predicted - label) > 5).item()\n",
    "                val_total += label.size(0)\n",
    "                \n",
    "            val_a_a = [v_correct_predictions_0_5, v_correct_predictions_1, v_correct_predictions_2, v_correct_predictions_5, v_correct_predictions_g_5]\n",
    "            val_a_acc.append(val_a_a)\n",
    "                \n",
    "        train_acc = (train_correct / (train_total))*100\n",
    "        val_acc = (val_correct / (val_total))*100\n",
    "        tloss = running_train_loss / len(train_dataloader)\n",
    "        vloss = running_val_loss/ len(val_dataloader)\n",
    "\n",
    "        print(\"Epoch\", epoch, \" Took\", int(time.time() - start), \"s\")\n",
    "        print(\"Train Acc:\", train_acc, \"Val Acc:\", val_acc)\n",
    "        print(\"Avg Train Loss:\", tloss, \"Avg Val Loss:\", vloss)\n",
    "\n",
    "        scheduler.step(vloss)\n",
    "\n",
    "        EPOCH_TRAIN_LOSSES.append(tloss)\n",
    "        EPOCH_VAL_LOSSES.append(vloss)\n",
    "        EPOCH_TRAIN_ACC.append(train_acc)\n",
    "        EPOCH_VAL_ACC.append(val_acc)\n",
    "\n",
    "        if save:\n",
    "            torch.save(model.state_dict(), './model_' + str(epoch + 1) + '_' + str(val_acc) + '.pt')\n",
    "            \n",
    "    return EPOCH_TRAIN_LOSSES, EPOCH_VAL_LOSSES, EPOCH_TRAIN_ACC, EPOCH_VAL_ACC, val_a_acc, train_a_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 13, 3, 30, 40])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 24 19 3 3, expected input[16, 9, 30, 40] to have 19 channels, but got 9 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b20f06e29dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_a_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_a_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-6b818a54ec03>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, model, save)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#             s = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m#             e = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#             print(e - s, \"time for f pass\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b2d07f16513e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mfeaturesV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DLProject/convLSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden_state)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 h, c = self.cell_list[layer_idx](input=cur_layer_input[:, t, :, :, :],\n\u001b[0;32m--> 136\u001b[0;31m                                                  prev_state=[h, c])\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0moutput_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DLProject/convLSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, prev_state)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# concatenate along channel axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mcombined_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mcc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 24 19 3 3, expected input[16, 9, 30, 40] to have 19 channels, but got 9 channels instead"
     ]
    }
   ],
   "source": [
    "n_epochs = 9\n",
    "t_l, v_l, t_a, v_a, val_a_acc, train_a_acc = train(n_epochs, f_model, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "objects = ('[0, 0.5]', '(0.5, 1]', '(1, 2]', '(2, 5]', '(5, Inf.)')\n",
    "performanceV = val_a_acc[-1]\n",
    "performanceT = train_a_acc[0]\n",
    "\n",
    "x = np.arange(len(objects))\n",
    "# print(v_all_a)\n",
    "width = 0.2 # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, performanceV, width, label=\"Validation\")\n",
    "rects1 = ax.bar(x + width/2, performanceT, width, label=\"Training\")\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Training Points')\n",
    "ax.set_title('Accuracy for Last Epoch')\n",
    "ax.set_xticks(x)\n",
    "plt.ylim(0, 100)\n",
    "labels = []\n",
    "totalV = sum(performanceV)\n",
    "totalT = sum(performanceT)\n",
    "\n",
    "for x in range(len(objects)):\n",
    "    labels.append(objects[x] + \"\\n\" + str(int((performanceV[x]/totalV)*100)) + \"%,\" + str(int((performanceT[x]/totalT)*100)) + \"%\")\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.savefig('Last_Epoch.png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "objects = ('[0, 0.5]', '(0.5, 1]', '(1, 2]', '(2, 5]', '(5, Inf.)')\n",
    "performanceV = val_a_acc[0]\n",
    "performanceT = train_a_acc[-1]\n",
    "\n",
    "x = np.arange(len(objects))\n",
    "# print(v_all_a)\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, performanceV, width, label=\"Validation\")\n",
    "rects1 = ax.bar(x + width/2, performanceT, width, label=\"Training\")\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Training Points')\n",
    "ax.set_title('Accuracy for First Epoch')\n",
    "ax.set_xticks(x)\n",
    "plt.ylim(0, 100)\n",
    "labels = []\n",
    "totalV = sum(performanceV)\n",
    "totalT = sum(performanceT)\n",
    "\n",
    "for x in range(len(objects)):\n",
    "    labels.append(objects[x] + \"\\n\" + str(int((performanceV[x]/totalV)*100)) + \"%,\" + str(int((performanceT[x]/totalT)*100)) + \"%\")\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.savefig('Zero_Epoch.png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(n_epochs)\n",
    "\n",
    "rangeVi = 0\n",
    "rangeVf = 9\n",
    "plt.plot(x[rangeVi:rangeVf], t_l[rangeVi:rangeVf], label=\"Train\")\n",
    "plt.plot(x[rangeVi:rangeVf], v_l[rangeVi:rangeVf], label=\"Validation\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Epochs vs Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('CNN3dLossFinal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "steering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
