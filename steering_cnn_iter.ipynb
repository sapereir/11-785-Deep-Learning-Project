{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWjp0YakvnjK"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.nn.utils.rnn import *\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from convLSTM import *\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_FQdqcCbdf_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if GPU else \"cpu\")\n",
    "cuda = torch.cuda.is_available()\n",
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete, took 1 seconds\n",
      "# Images loaded:  300\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "angles = []\n",
    "torques = []\n",
    "speeds = []\n",
    "dataType = \"center\"\n",
    "numDataPointsWanted = 3000 #Might want to change this\n",
    "\n",
    "transform=transforms.ToTensor()\n",
    "root_path = \"./\"\n",
    "with open(root_path + \"labels.txt\") as f:\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        [filename, radians, torque, speed] = line.split(' ')\n",
    "        \n",
    "        if filename[0:4] == \"left\" and dataType == \"left\":\n",
    "            with Image.open(root_path + filename) as img:\n",
    "                X.append(transform(img.convert('RGB')))\n",
    "            angles.append(((float(radians) * 180.0)/np.pi))\n",
    "            torques.append(torque)\n",
    "            speeds.append(speed)\n",
    "            i += 1\n",
    "            \n",
    "        if filename[0:5] == \"right\" and dataType == \"right\":\n",
    "            with Image.open(root_path + filename) as img:\n",
    "                X.append(transform(img.convert('RGB')))\n",
    "            angles.append(((float(radians) * 180.0)/np.pi))\n",
    "            torques.append(torque)\n",
    "            speeds.append(speed)\n",
    "            i += 1\n",
    "                \n",
    "        if filename[0:6] == \"center\" and dataType == \"center\":\n",
    "            with Image.open(root_path + filename) as img:\n",
    "                X.append(transform(img.convert('RGB')))\n",
    "            angles.append((float(radians) * 180.0)/np.pi)\n",
    "            torques.append(torque)\n",
    "            speeds.append(speed)\n",
    "            i += 1\n",
    "            \n",
    "        if i == numDataPointsWanted: break\n",
    "    end = time.time()\n",
    "    \n",
    "\n",
    "print(\"Data loading complete, took\", int(end - start), \"seconds\")\n",
    "print('# Images loaded: ', len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Model(data.Dataset):\n",
    "    def __init__(self, X, Y, context_size=15):\n",
    "        self.X = []\n",
    "        angles = Y[:,0]\n",
    "        torques = Y[:,1]\n",
    "        speeds = Y[:,2]\n",
    "        self.angles = []\n",
    "        self.torques = []\n",
    "        self.speeds = []\n",
    "        for i in range(context_size, len(X)):\n",
    "            x = [torch.as_tensor(arr) for arr in X[i-context_size:i]]\n",
    "            self.X.append(torch.stack(x))\n",
    "            self.angles.append(angles[i])\n",
    "            self.torques.append(torques[i])\n",
    "            self.speeds.append(speeds[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index].float(), self.Y[index], self.torques[index], self.speeds[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.stack([np.array(angles), np.array(torques), np.array(speeds)]).T\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c844304dbbc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cuda' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "num_workers = 0 if cuda else 0\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.20)\n",
    "print(train_Y.shape)\n",
    "\n",
    "train_set = Dataset_Model(train_X, train_Y, context_size=15)\n",
    "train_dataloader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "val_set = Dataset_Model(val_X, val_Y, context_size=15)\n",
    "val_dataloader = data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-67c450027a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_set' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "\n",
    "print(train_set.__getitem__(0)[0].shape, train_set.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Q7kgXqOJooJ"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=(1, 4, 4), stride=2, padding=2)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 12, 12), stride=4, padding=2)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(out_channels, out_channels, kernel_size=(1, 4, 4), stride=2, padding=2)\n",
    "        self.bn3 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.avgpool = nn.AvgPool3d(1)\n",
    "        \n",
    "#         self.convLSTM = ConvLSTM(input_size=(30, 40), input_dim=out_channels, \n",
    "#                                     hidden_dim=out_channels//2, kernel_size=(3, 3), num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x) \n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        output = self.avgpool(output)\n",
    "        \n",
    "#         print(output.shape)\n",
    "        hidden = None\n",
    "#         output, hidden = self.convLSTM(output, hidden)\n",
    "        \n",
    "        featuresV = output.reshape(output.size(0), -1)\n",
    "        output = self.fc(featuresV)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXbF3bm9eqsz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv3d(15, 13, kernel_size=(1, 4, 4), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "  (bn1): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv3d(13, 13, kernel_size=(3, 12, 12), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "  (bn2): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv3d(13, 13, kernel_size=(1, 4, 4), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "  (bn3): BatchNorm3d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (avgpool): AvgPool3d(kernel_size=1, stride=1, padding=0)\n",
      "  (convLSTM): ConvLSTM(\n",
      "    (cell_list): ModuleList(\n",
      "      (0): ConvLSTMCell(\n",
      "        (conv): Conv2d(19, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=46800, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "context_size = 15\n",
    "out_channels = 13\n",
    "input_size = 46800\n",
    "f_model = CNN(context_size, out_channels, input_size, 1).to(device)\n",
    "optimizer = torch.optim.Adam(f_model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x, y):\n",
    "    total = 0\n",
    "    for v in range(len(x)):\n",
    "        if x[v] and y[v]:\n",
    "            total += 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6nDA4eylV6N"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, save):\n",
    "    EPOCH_TRAIN_LOSSES = []\n",
    "    EPOCH_VAL_LOSSES = []\n",
    "    EPOCH_TRAIN_ACC = []\n",
    "    EPOCH_VAL_ACC = []\n",
    "    train_a_acc = []\n",
    "    val_a_acc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        running_train_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "        train_correct = 0.0\n",
    "        val_correct = 0.0\n",
    "        train_total = 0.0\n",
    "        val_total = 0.0\n",
    "               \n",
    "        t_correct_predictions_0_5 = 0.0\n",
    "        t_correct_predictions_1 = 0.0\n",
    "        t_correct_predictions_2 = 0.0\n",
    "        t_correct_predictions_5 = 0.0\n",
    "        t_correct_predictions_g_5 = 0.0\n",
    "        \n",
    "        v_correct_predictions_0_5 = 0.0\n",
    "        v_correct_predictions_1 = 0.0\n",
    "        v_correct_predictions_2 = 0.0\n",
    "        v_correct_predictions_5 = 0.0\n",
    "        v_correct_predictions_g_5 = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (x, label) in enumerate(train_dataloader):\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             s = time.time()\n",
    "            y = model(x.float()).double().squeeze(1)\n",
    "#             e = time.time()\n",
    "#             print(e - s, \"time for f pass\")\n",
    "            \n",
    "            loss = criterion(y, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            predicted = y            \n",
    "            train_correct += torch.sum(torch.abs(predicted - label) < 0.1).item()\n",
    "            t_correct_predictions_0_5 += torch.sum(torch.abs(predicted - label) <= 0.5).item()\n",
    "            t_correct_predictions_1 += combine(torch.abs(predicted - label) > 0.5,  torch.abs(predicted - label) <= 1)\n",
    "            t_correct_predictions_2 += combine(torch.abs(predicted - label) > 1,  torch.abs(predicted - label) <= 2)\n",
    "            t_correct_predictions_5 += combine(torch.abs(predicted - label) > 2,  torch.abs(predicted - label) <= 5)\n",
    "            v_correct_predictions_g_5 += torch.sum(torch.abs(predicted - label) > 5).item()\n",
    "            train_total += label.size(0)\n",
    "            \n",
    "            del x\n",
    "            del label\n",
    "                    \n",
    "        train_a_a = [t_correct_predictions_0_5, t_correct_predictions_1, t_correct_predictions_2, t_correct_predictions_5, t_correct_predictions_g_5]\n",
    "        train_a_acc.append(train_a_a)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (x, label) in enumerate(val_dataloader):\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                y = model(x.float()).double().squeeze(1)\n",
    "                \n",
    "                loss = criterion(y, label)\n",
    "\n",
    "                running_val_loss += loss.item()\n",
    "                predicted = y\n",
    "                val_correct += torch.sum(torch.abs(predicted - label) < 0.1).item()\n",
    "                v_correct_predictions_0_5 += torch.sum(torch.abs(predicted - label) <= 0.5).item()\n",
    "                v_correct_predictions_1 += combine(torch.abs(predicted - label) > 0.5,  torch.abs(predicted - label) <= 1)\n",
    "                v_correct_predictions_2 += combine(torch.abs(predicted - label) > 1,  torch.abs(predicted - label) <= 2)\n",
    "                v_correct_predictions_5 += combine(torch.abs(predicted - label) > 2,  torch.abs(predicted - label) <= 5)\n",
    "                v_correct_predictions_g_5 += torch.sum(torch.abs(predicted - label) > 5).item()\n",
    "                val_total += label.size(0)\n",
    "                \n",
    "            val_a_a = [v_correct_predictions_0_5, v_correct_predictions_1, v_correct_predictions_2, v_correct_predictions_5, v_correct_predictions_g_5]\n",
    "            val_a_acc.append(val_a_a)\n",
    "                \n",
    "        train_acc = (train_correct / (train_total))*100\n",
    "        val_acc = (val_correct / (val_total))*100\n",
    "        tloss = running_train_loss / len(train_dataloader)\n",
    "        vloss = running_val_loss/ len(val_dataloader)\n",
    "\n",
    "        print(\"Epoch\", epoch, \" Took\", int(time.time() - start), \"s\")\n",
    "        print(\"Train Acc:\", train_acc, \"Val Acc:\", val_acc)\n",
    "        print(\"Avg Train Loss:\", tloss, \"Avg Val Loss:\", vloss)\n",
    "\n",
    "        scheduler.step(vloss)\n",
    "\n",
    "        EPOCH_TRAIN_LOSSES.append(tloss)\n",
    "        EPOCH_VAL_LOSSES.append(vloss)\n",
    "        EPOCH_TRAIN_ACC.append(train_acc)\n",
    "        EPOCH_VAL_ACC.append(val_acc)\n",
    "\n",
    "        if save:\n",
    "            torch.save(model.state_dict(), './model_' + str(epoch + 1) + '_' + str(val_acc) + '.pt')\n",
    "            \n",
    "    return EPOCH_TRAIN_LOSSES, EPOCH_VAL_LOSSES, EPOCH_TRAIN_ACC, EPOCH_VAL_ACC, val_a_acc, train_a_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 9\n",
    "t_l, v_l, t_a, v_a, val_a_acc, train_a_acc = train(n_epochs, f_model, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "objects = ('[0, 0.5]', '(0.5, 1]', '(1, 2]', '(2, 5]', '(5, Inf.)')\n",
    "performanceV = val_a_acc[-1]\n",
    "performanceT = train_a_acc[0]\n",
    "\n",
    "x = np.arange(len(objects))\n",
    "# print(v_all_a)\n",
    "width = 0.2 # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, performanceV, width, label=\"Validation\")\n",
    "rects1 = ax.bar(x + width/2, performanceT, width, label=\"Training\")\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Training Points')\n",
    "ax.set_title('Accuracy for Last Epoch')\n",
    "ax.set_xticks(x)\n",
    "plt.ylim(0, 100)\n",
    "labels = []\n",
    "totalV = sum(performanceV)\n",
    "totalT = sum(performanceT)\n",
    "\n",
    "for x in range(len(objects)):\n",
    "    labels.append(objects[x] + \"\\n\" + str(int((performanceV[x]/totalV)*100)) + \"%,\" + str(int((performanceT[x]/totalT)*100)) + \"%\")\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.savefig('Last_Epoch.png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "objects = ('[0, 0.5]', '(0.5, 1]', '(1, 2]', '(2, 5]', '(5, Inf.)')\n",
    "performanceV = val_a_acc[0]\n",
    "performanceT = train_a_acc[-1]\n",
    "\n",
    "x = np.arange(len(objects))\n",
    "# print(v_all_a)\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, performanceV, width, label=\"Validation\")\n",
    "rects1 = ax.bar(x + width/2, performanceT, width, label=\"Training\")\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Training Points')\n",
    "ax.set_title('Accuracy for First Epoch')\n",
    "ax.set_xticks(x)\n",
    "plt.ylim(0, 100)\n",
    "labels = []\n",
    "totalV = sum(performanceV)\n",
    "totalT = sum(performanceT)\n",
    "\n",
    "for x in range(len(objects)):\n",
    "    labels.append(objects[x] + \"\\n\" + str(int((performanceV[x]/totalV)*100)) + \"%,\" + str(int((performanceT[x]/totalT)*100)) + \"%\")\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.savefig('Zero_Epoch.png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(n_epochs)\n",
    "\n",
    "rangeVi = 0\n",
    "rangeVf = 9\n",
    "plt.plot(x[rangeVi:rangeVf], t_l[rangeVi:rangeVf], label=\"Train\")\n",
    "plt.plot(x[rangeVi:rangeVf], v_l[rangeVi:rangeVf], label=\"Validation\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Epochs vs Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('CNN3dLossFinal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "steering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
